"""
This type stub file was generated by pyright.
"""

from typing import Any, Optional

"""
These method recursively evaluate the SPARQL Algebra

evalQuery is the entry-point, it will setup context and
return the SPARQLResult object

evalPart is called on each level and will delegate to the right method

A rdflib.plugins.sparql.sparql.QueryContext is passed along, keeping
information needed for evaluation

A list of dicts (solution mappings) is returned, apart from GroupBy which may
also return a dict of list of dicts

"""
def evalBGP(ctx, bgp):
    """
    A basic graph pattern
    """
    ...

def evalExtend(ctx, extend):
    ...

def evalLazyJoin(ctx, join):
    """
    A lazy join will push the variables bound
    in the first part to the second part,
    essentially doing the join implicitly
    hopefully evaluating much fewer triples
    """
    ...

def evalJoin(ctx, join):
    ...

def evalUnion(ctx, union):
    ...

def evalMinus(ctx, minus):
    ...

def evalLeftJoin(ctx, join):
    ...

def evalFilter(ctx, part):
    ...

def evalGraph(ctx, part):
    ...

def evalValues(ctx, part):
    ...

def evalMultiset(ctx, part):
    ...

def evalPart(ctx, part):
    ...

def evalGroup(ctx, group):
    """
    http://www.w3.org/TR/sparql11-query/#defn_algGroup
    """
    ...

def evalAggregateJoin(ctx, agg):
    ...

def evalOrderBy(ctx, part):
    ...

def evalSlice(ctx, slice):
    ...

def evalReduced(ctx, part):
    """apply REDUCED to result

    REDUCED is not as strict as DISTINCT, but if the incoming rows were sorted
    it should produce the same result with limited extra memory and time per
    incoming row.
    """
    ...

def evalDistinct(ctx, part):
    ...

def evalProject(ctx, project):
    ...

def evalSelectQuery(ctx, query):
    ...

def evalAskQuery(ctx, query):
    ...

def evalConstructQuery(ctx, query):
    ...

def evalQuery(graph, query, initBindings, base: Optional[Any] = ...):
    ...

