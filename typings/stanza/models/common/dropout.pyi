"""
This type stub file was generated by pyright.
"""

import torch.nn as nn
from typing import Any, Optional

class WordDropout(nn.Module):
    """ A word dropout layer that's designed for embedded inputs (e.g., any inputs to an LSTM layer).
    Given a batch of embedded inputs, this layer randomly set some of them to be a replacement state.
    Note that this layer assumes the last dimension of the input to be the hidden dimension of a unit.
    """
    def __init__(self, dropprob):
        self.dropprob = ...
    
    def forward(self, x, replacement: Optional[Any] = ...):
        ...
    
    def extra_repr(self):
        ...
    


class LockedDropout(nn.Module):
    """
    A variant of dropout layer that consistently drops out the same parameters over time. Also known as the variational dropout. 
    This implentation was modified from the LockedDropout implementation in the flair library (https://github.com/zalandoresearch/flair).
    """
    def __init__(self, dropprob, batch_first: bool = ...):
        self.dropprob = ...
        self.batch_first = ...
    
    def forward(self, x):
        ...
    
    def extra_repr(self):
        ...
    


class SequenceUnitDropout(nn.Module):
    """ A unit dropout layer that's designed for input of sequence units (e.g., word sequence, char sequence, etc.).
    Given a sequence of unit indices, this layer randomly set some of them to be a replacement id (usually set to be <UNK>).
    """
    def __init__(self, dropprob, replacement_id):
        self.dropprob = ...
        self.replacement_id = ...
    
    def forward(self, x):
        """ :param: x must be a LongTensor of unit indices. """
        ...
    
    def extra_repr(self):
        ...
    


