"""
This type stub file was generated by pyright.
"""

from typing import Any, Optional

class ParserGeneratorError(Exception):
  ...


class LexingError(Exception):
  def __init__(self, message, source_pos):
    self.message = ...
    self.source_pos = ...
  


class ParsingError(Exception):
  def __init__(self, message, source_pos):
    self.message = ...
    self.source_pos = ...
  


class IdentityDict(object):
  def __init__(self):
    ...
  
  def get(self, key, default: Optional[Any] = ...):
    ...
  
  def __getitem__(self, key):
    ...
  
  def __setitem__(self, key, value):
    ...
  
  def __delitem__(self, key):
    ...
  
  def __len__(self):
    ...
  
  def __iter__(self):
    ...
  


class Counter(object):
  def __init__(self):
    self.value = ...
  
  def incr(self):
    ...
  


class Token(object):
  alias = ...
  def __init__(self, name, value, source_pos: Optional[Any] = ...):
    self.name = ...
    self.value = ...
    self.source_pos = ...
  
  def __repr__(self):
    ...
  
  def __eq__(self, other):
    ...
  
  def __hash__(self):
    ...
  


def rightmost_terminal(symbols, terminals):
  ...

class Grammar(object):
  def __init__(self, terminals):
    self.productions = ...
    self.prod_names = ...
    self.terminals = ...
    self.nonterminals = ...
    self.first = ...
    self.follow = ...
    self.precedence = ...
    self.start = ...
  
  def add_production(self, prod_name, syms, func, precedence):
    ...
  
  def set_precedence(self, term, assoc, level):
    ...
  
  def set_start(self):
    self.start = ...
  
  def unused_terminals(self):
    ...
  
  def unused_productions(self):
    ...
  
  def build_lritems(self):
    ...
  
  def _first(self, beta):
    ...
  
  def compute_first(self):
    ...
  
  def compute_follow(self):
    ...
  


class Production(object):
  def __init__(self, num, name, prod, precedence, func):
    self.name = ...
    self.prod = ...
    self.number = ...
    self.func = ...
    self.prec = ...
    self.unique_syms = ...
    self.lr_items = ...
    self.lr_next = ...
    self.lr0_added = ...
    self.reduced = ...
  
  def __repr__(self):
    ...
  
  def getlength(self):
    ...
  


class LRItem(object):
  def __init__(self, p, n, before, after):
    self.name = ...
    self.prod = ...
    self.number = ...
    self.lr_index = ...
    self.lookaheads = ...
    self.unique_syms = ...
    self.lr_before = ...
    self.lr_after = ...
  
  def __repr__(self):
    ...
  
  def getlength(self):
    ...
  


class Lexer(object):
  def __init__(self, rules, ignore_rules):
    self.rules = ...
    self.ignore_rules = ...
  
  def lex(self, s):
    ...
  


class LexerStream(object):
  def __init__(self, lexer, s):
    self.lexer = ...
    self.s = ...
    self.idx = ...
  
  def __iter__(self):
    ...
  
  def next(self):
    ...
  
  __next__ = ...


class LexerGenerator(object):
  def __init__(self):
    self.rules = ...
    self.ignore_rules = ...
  
  def add(self, name, pattern, flags=...):
    ...
  
  def ignore(self, pattern, flags=...):
    ...
  
  def build(self):
    ...
  


class LRParser(object):
  def __init__(self, lr_table, error_handler):
    self.lr_table = ...
    self.error_handler = ...
  
  def parse(self, tokenizer, state: Optional[Any] = ...):
    ...
  
  def _reduce_production(self, t, symstack, statestack, state):
    ...
  


LARGE_VALUE = 9223372036854776000
class ParserGenerator(object):
  def __init__(self, tokens, precedence=..., cache_id: Optional[Any] = ...):
    self.tokens = ...
    self.productions = ...
    self.precedence = ...
    self.cache_id = ...
    self.error_handler = ...
  
  def production(self, rule, precedence: Optional[Any] = ...):
    ...
  
  def error(self, func):
    self.error_handler = ...
  
  def data_is_valid(self, g, data):
    ...
  
  def build(self):
    ...
  


def digraph(X, R, FP):
  ...

def traverse(x, N, stack, F, X, R, FP):
  ...

class LRTable(object):
  def __init__(self, grammar, lr_action, lr_goto, default_reductions, sr_conflicts, rr_conflicts):
    self.grammar = ...
    self.lr_action = ...
    self.lr_goto = ...
    self.default_reductions = ...
    self.sr_conflicts = ...
    self.rr_conflicts = ...
  
  @classmethod
  def from_cache(cls, grammar, data):
    ...
  
  @classmethod
  def from_grammar(cls, grammar):
    ...
  
  @classmethod
  def lr0_items(cls, grammar, add_count, cidhash, goto_cache):
    ...
  
  @classmethod
  def lr0_closure(cls, I, add_count):
    ...
  
  @classmethod
  def lr0_goto(cls, I, x, add_count, goto_cache):
    ...
  
  @classmethod
  def add_lalr_lookaheads(cls, grammar, C, add_count, cidhash, goto_cache):
    ...
  
  @classmethod
  def compute_nullable_nonterminals(cls, grammar):
    ...
  
  @classmethod
  def find_nonterminal_transitions(cls, grammar, C):
    ...
  
  @classmethod
  def compute_read_sets(cls, grammar, C, ntrans, nullable, add_count, cidhash, goto_cache):
    ...
  
  @classmethod
  def compute_follow_sets(cls, ntrans, readsets, includesets):
    ...
  
  @classmethod
  def dr_relation(cls, grammar, C, trans, nullable, add_count, goto_cache):
    ...
  
  @classmethod
  def reads_relation(cls, C, trans, empty, add_count, cidhash, goto_cache):
    ...
  
  @classmethod
  def compute_lookback_includes(cls, grammar, C, trans, nullable, add_count, cidhash, goto_cache):
    ...
  
  @classmethod
  def add_lookaheads(cls, lookbacks, followset):
    ...
  


